{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 style=\"text-align:center;background-color:DarkTurquoise; color:Teal; font-size: 40px\">5. Sailing Towards Sentience\n<img src=\"https://uploads-ssl.webflow.com/615bf2d50c4d2f10541ef9a1/61d48ffd38497b2c56571a0d_Univ.AI%20Logo_darkbg.svg\" style=\"width:200px;height:200px;\"></h1>\n<div class=\"alert alert-info\" role=\"alert\">\n  <b>Team :</b><br>\n  <span style=\"color: Teal; font-weight: bold; font-size: 40px\">The Sentient Chef </span><br>\n  <span style=\"color: LightSeaGreen; font-weight: bold; font-size: 20px;\">Univ.AI DS-1 C5 Final Project</span><br><br>\n  <b>Voyage Controller :</b><br>\n  <span style=\"color: LightSeaGreen; font-weight: bold;\">Shibani Budhraja </span><br><br>\n  <b>On Board Crews :</b><br>\n  <span style=\"color: LightSeaGreen; font-weight: bold;\">1. Swarnava Bhattacharjee</span><br>\n  <span style=\"color: LightSeaGreen; font-weight: bold;\">2. Karthik Rathod</span><br>\n  <span style=\"color: LightSeaGreen; font-weight: bold;\">3. Yamuna Katta</span><br>\n  <span style=\"color: LightSeaGreen; font-weight: bold;\">4. Venkatesh BY</span><br></div>","metadata":{}},{"cell_type":"markdown","source":"![recommendation](https://i.imgur.com/aUFb99f.jpeg)\nThe above image is built with AI model, ¬©Ô∏èThe Sentient Chef ","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-warning\" role=\"alert\">\n    <b>Decisions:</b> We considered the <b>gensim</b> library as it is open-source library for natural language processing (NLP) and topic modeling, which can also be used for recommendation systems.\n    <br><br>\n    <ul>\n        <li><b>Efficient algorithms:</b> Gensim uses efficient algorithms for text processing, such as the Latent Dirichlet Allocation (LDA) algorithm, which can be used for topic modeling and can also be adapted for recommendation systems.</li>\n        <li><b>Scalability:</b> Gensim is designed to handle large datasets and can scale well to large amounts of data, making it suitable for building recommendation systems that need to handle large volumes of user interactions and item data.</li>\n    </ul>\n</div> ","metadata":{}},{"cell_type":"markdown","source":"<h1 style=\"text-align:center;background-color:#117864; color:white\" >Installing the gensim library for building Recommendation System.</h1>\n<div class=\"alert alert-success\" role=\"alert\">\n    <b> Gensim </b> is a free open-source Python library for representing documents as semantic vectors, as efficiently (computer-wise) and painlessly (human-wise) as possible. Gensim is designed to process raw, unstructured digital texts (‚Äúplain text‚Äù) using unsupervised machine learning algorithms.\n</div>","metadata":{}},{"cell_type":"code","source":"!pip install gensim","metadata":{"execution":{"iopub.status.busy":"2023-03-13T14:54:36.341556Z","iopub.status.idle":"2023-03-13T14:54:36.343172Z","shell.execute_reply.started":"2023-03-13T14:54:36.342822Z","shell.execute_reply":"2023-03-13T14:54:36.342864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing necessary libraries\nimport pandas as pd\nimport numpy as np\nimport re\nimport collections\nimport warnings\nimport nltk\nwarnings.filterwarnings('ignore')\n\nfrom gensim.corpora import Dictionary\nfrom gensim.models.lsimodel import LsiModel\nfrom gensim.similarities import MatrixSimilarity\n","metadata":{"execution":{"iopub.status.busy":"2023-03-13T14:54:36.352809Z","iopub.execute_input":"2023-03-13T14:54:36.353624Z","iopub.status.idle":"2023-03-13T14:54:37.955791Z","shell.execute_reply.started":"2023-03-13T14:54:36.353568Z","shell.execute_reply":"2023-03-13T14:54:37.954434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"text-align:center;background-color:#117864; color:white\" >Defining Functions</h2>","metadata":{}},{"cell_type":"code","source":"def convert_tolist(x):\n    \"\"\"\n    Converts a string representation of a list into a list object.\n\n    Args:\n    - x (str): a string representation of a list, e.g., \"['a', 'b', 'c']\"\n\n    Returns:\n    - y (list): a list object created from the input string\n    \"\"\"\n    \n    y = eval(x)\n    return y","metadata":{"execution":{"iopub.status.busy":"2023-03-13T14:54:37.960205Z","iopub.execute_input":"2023-03-13T14:54:37.960904Z","iopub.status.idle":"2023-03-13T14:54:37.968019Z","shell.execute_reply.started":"2023-03-13T14:54:37.960845Z","shell.execute_reply":"2023-03-13T14:54:37.966801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_ingerdients(x):\n    \"\"\"\n    Returns a filtered list of ingredients that appear more than 2 times in the input list.\n\n    Args:\n    - x (list): a list of strings representing ingredients\n\n    Returns:\n    - filtered_list (list): a list of strings representing ingredients that appear more than 2 times in the input list\n    \"\"\"\n    filtered_list = []\n    for i in x:\n        try:\n            if counts.get(i) > 2:\n                filtered_list.append(i)\n        except:\n            pass\n    return filtered_list","metadata":{"execution":{"iopub.status.busy":"2023-03-13T14:54:37.969771Z","iopub.execute_input":"2023-03-13T14:54:37.970126Z","iopub.status.idle":"2023-03-13T14:54:37.983099Z","shell.execute_reply.started":"2023-03-13T14:54:37.970091Z","shell.execute_reply":"2023-03-13T14:54:37.981941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def list_to_string(ingredient_list):\n    \"\"\"\n    Converts a list of ingredients into a string with each ingredient separated by a space.\n\n    Args:\n        ingredient_list (list): A list of strings representing the ingredients.\n\n    Returns:\n        str: A string representation of the ingredients, with each ingredient separated by a space.\n\n    Example:\n        >>> ingredients = [\"flour\", \"sugar\", \"butter\", \"eggs\"]\n        >>> list_to_string(ingredients)\n        'flour sugar butter eggs'\n    \"\"\"\n    return ' '.join(ingredient_list)","metadata":{"execution":{"iopub.status.busy":"2023-03-13T14:54:37.986230Z","iopub.execute_input":"2023-03-13T14:54:37.986684Z","iopub.status.idle":"2023-03-13T14:54:37.997386Z","shell.execute_reply.started":"2023-03-13T14:54:37.986641Z","shell.execute_reply":"2023-03-13T14:54:37.996377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"text-align:center;background-color:#117864; color:white\" >Feature Preprocessing</h2>","metadata":{}},{"cell_type":"code","source":"# Importing the requried csv file for recommendation\ndf = pd.read_csv(\"/kaggle/input/the-sentient-chef-notebook-eda/df_diet_type.csv\")\ndf_diet = df[['title','ingredients','diet_type','description','URL']]\ndf_diet.shape","metadata":{"execution":{"iopub.status.busy":"2023-03-13T14:54:37.998725Z","iopub.execute_input":"2023-03-13T14:54:37.999688Z","iopub.status.idle":"2023-03-13T14:54:38.687983Z","shell.execute_reply.started":"2023-03-13T14:54:37.999646Z","shell.execute_reply":"2023-03-13T14:54:38.686776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# converting the datatype of the ingerdients data-points from string to list\ndf_diet.ingredients = df_diet.ingredients.apply(convert_tolist)","metadata":{"execution":{"iopub.status.busy":"2023-03-13T14:54:38.708769Z","iopub.execute_input":"2023-03-13T14:54:38.709592Z","iopub.status.idle":"2023-03-13T14:54:39.053158Z","shell.execute_reply.started":"2023-03-13T14:54:38.709535Z","shell.execute_reply":"2023-03-13T14:54:39.051986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating the list of all the ingerdients in the data frame to be used in filteration\nlist_ingeredients = []\nfor i in df_diet['ingredients']:\n    for j in range(len(i)):\n        list_ingeredients.append(i[j])\nlen(list_ingeredients)","metadata":{"execution":{"iopub.status.busy":"2023-03-13T14:54:39.054752Z","iopub.execute_input":"2023-03-13T14:54:39.055125Z","iopub.status.idle":"2023-03-13T14:54:39.109430Z","shell.execute_reply.started":"2023-03-13T14:54:39.055088Z","shell.execute_reply":"2023-03-13T14:54:39.108162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using nltk to seperate the words in the list by taging them based on parts of speech\npos_tags = nltk.pos_tag(list_ingeredients)\n\n# selecting only those words which are tagged with noun\nnouns = [word for (word, pos) in pos_tags if pos.startswith('N')]\n","metadata":{"execution":{"iopub.status.busy":"2023-03-13T14:54:39.110918Z","iopub.execute_input":"2023-03-13T14:54:39.112074Z","iopub.status.idle":"2023-03-13T14:54:53.269943Z","shell.execute_reply.started":"2023-03-13T14:54:39.112032Z","shell.execute_reply":"2023-03-13T14:54:53.268463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# there might be words with are not nouns and yet not discarded \n# to filter them out we will be dropping words whos length is less than 2 letters\nfiltered_words = [word for word in nouns if len(word) > 2]\nlen(filtered_words)","metadata":{"execution":{"iopub.status.busy":"2023-03-13T14:54:53.273148Z","iopub.execute_input":"2023-03-13T14:54:53.273563Z","iopub.status.idle":"2023-03-13T14:54:53.301701Z","shell.execute_reply.started":"2023-03-13T14:54:53.273521Z","shell.execute_reply":"2023-03-13T14:54:53.300483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# using counter from collections library we will get the frequeincy of the word in whole list\ncounts = collections.Counter(filtered_words)\nlen(counts.keys())","metadata":{"execution":{"iopub.status.busy":"2023-03-13T14:54:53.303325Z","iopub.execute_input":"2023-03-13T14:54:53.303854Z","iopub.status.idle":"2023-03-13T14:54:53.322957Z","shell.execute_reply.started":"2023-03-13T14:54:53.303806Z","shell.execute_reply":"2023-03-13T14:54:53.321680Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# the counts dictionary created above will be used to filter the ingerdients from the individual recipes using the remove_ingerdients function\ndf_diet.ingredients = df_diet.ingredients.apply(remove_ingerdients)","metadata":{"execution":{"iopub.status.busy":"2023-03-13T12:26:39.349788Z","iopub.execute_input":"2023-03-13T12:26:39.350100Z","iopub.status.idle":"2023-03-13T12:26:39.429957Z","shell.execute_reply.started":"2023-03-13T12:26:39.350071Z","shell.execute_reply":"2023-03-13T12:26:39.428719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# saving the dataframe to be further use in model deployment\ndf_diet.to_csv(\"Recommendation_data.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2023-03-13T12:26:39.475209Z","iopub.execute_input":"2023-03-13T12:26:39.475703Z","iopub.status.idle":"2023-03-13T12:26:39.609074Z","shell.execute_reply.started":"2023-03-13T12:26:39.475654Z","shell.execute_reply":"2023-03-13T12:26:39.607281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we will be dividing the dataset in three dataframe where division will be based on diet type of recipe\ndf_diet_non_veg = df_diet[df_diet['diet_type'] == 'nveg'].reset_index(drop = True).copy()\ndf_diet_veg = df_diet[df_diet['diet_type'] == 'veg'].reset_index(drop = True).copy()\ndf_diet_vegan = df_diet[df_diet['diet_type'] == 'vegan'].reset_index(drop = True).copy()\n","metadata":{"execution":{"iopub.status.busy":"2023-03-13T12:26:39.610727Z","iopub.execute_input":"2023-03-13T12:26:39.611088Z","iopub.status.idle":"2023-03-13T12:26:39.638827Z","shell.execute_reply.started":"2023-03-13T12:26:39.611054Z","shell.execute_reply":"2023-03-13T12:26:39.636566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"text-align:center;background-color:#117864; color:white\" >Model Building :</h1>\n<div class=\"alert alert-success\" role=\"alert\">\n    The models below uses the Gensim library to create an <b>LSI (Latent Semantic Indexing)</b> topic model and a similarity index for a collection of recipe ingredients. The function takes a pandas DataFrame containing recipe ingredients, creates a bag-of-words representation of the ingredients, creates an LSI topic model from the bag-of-words representation, and creates a similarity index for the topic model. The similarity index will used to identify recipes that are most similar to a user's input ingredients.\n</div>","metadata":{}},{"cell_type":"code","source":"#Generating a dictionary from the one-hot encoded ingredients\ningredient_dict_0 = Dictionary(df_diet['ingredients'].apply(lambda x: x.split()))\n\n#Generating a bag-of-words representation of the ingredient data\ningredient_bow = [ingredient_dict_0.doc2bow(recipe.split()) for recipe in df_diet['ingredients']]\n\n#Creating an LSI topic model from the ingredient data\nmodel_0 = LsiModel(corpus=ingredient_bow, id2word=ingredient_dict_0, num_topics=len(df_diet['ingredients']))\n\n#Creating a matrix similarity index for the topic model\nindex_0 = MatrixSimilarity(model_0[ingredient_bow])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"text-align:center;background-color:#1F618D; color:white\" >SUPRISE-ME</h2>\n<div class=\"alert alert-info\" role=\"alert\">\n    This model will be recommendating from the data set conating all the recipes.\n</div>","metadata":{}},{"cell_type":"code","source":"\n#Generating a dictionary from the one-hot encoded ingredients\ningredient_dict_0 = Dictionary(df_diet['ingredients'].apply(lambda x: x.split()))\n\n#Generating a bag-of-words representation of the ingredient data\ningredient_bow = [ingredient_dict_0.doc2bow(recipe.split()) for recipe in df_diet['ingredients']]\n\n#Creating an LSI topic model from the ingredient data\nmodel_0 = LsiModel(corpus=ingredient_bow, id2word=ingredient_dict_0, num_topics=len(df_diet['ingredients']))\n\n#Creating a matrix similarity index for the topic model\nindex_0 = MatrixSimilarity(model_0[ingredient_bow])\n\n","metadata":{"execution":{"iopub.status.busy":"2023-03-13T12:26:39.640448Z","iopub.execute_input":"2023-03-13T12:26:39.641648Z","iopub.status.idle":"2023-03-13T12:27:20.698321Z","shell.execute_reply.started":"2023-03-13T12:26:39.641604Z","shell.execute_reply":"2023-03-13T12:27:20.696588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"text-align:center;background-color:#1F618D; color:white\" >NON-VEG</h2>\n<div class=\"alert alert-info\" role=\"alert\">\n    This model will be recommendating from the data set conating all the Non_veg recipes\n</div>","metadata":{}},{"cell_type":"code","source":"\n#Generating a dictionary from the one-hot encoded ingredients\ningredient_dict_1 = Dictionary(df_diet_non_veg['ingredients'].apply(lambda x: x.split()))\n\n#Generating a bag-of-words representation of the ingredient data\ningredient_bow = [ingredient_dict_1.doc2bow(recipe.split()) for recipe in df_diet_non_veg['ingredients']]\n\n#Creating an LSI topic model from the ingredient data\nmodel_1 = LsiModel(corpus=ingredient_bow, id2word=ingredient_dict_1, num_topics=len(df_diet_non_veg['ingredients']))\n\n#Creating a matrix similarity index for the topic model\nindex_1 = MatrixSimilarity(model_1[ingredient_bow])\n\n","metadata":{"execution":{"iopub.status.busy":"2023-03-13T12:27:20.700448Z","iopub.execute_input":"2023-03-13T12:27:20.700828Z","iopub.status.idle":"2023-03-13T12:27:42.989149Z","shell.execute_reply.started":"2023-03-13T12:27:20.700789Z","shell.execute_reply":"2023-03-13T12:27:42.987835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"text-align:center;background-color:#1F618D; color:white\" >VEG</h2>\n<div class=\"alert alert-info\" role=\"alert\">\n    This model will be recommendating from the data set conating all the veg recipes\n</div>","metadata":{}},{"cell_type":"code","source":"\n#Generating a dictionary from the one-hot encoded ingredients\ningredient_dict_2 = Dictionary(df_diet_veg['ingredients'].apply(lambda x: x.split()))\n\n#Generating a bag-of-words representation of the ingredient data\ningredient_bow = [ingredient_dict_2.doc2bow(recipe.split()) for recipe in df_diet_veg['ingredients']]\n\n#Creating an LSI topic model from the ingredient data\nmodel_2 = LsiModel(corpus=ingredient_bow, id2word=ingredient_dict_2, num_topics=len(df_diet_veg['ingredients']))\n\n#Creating a matrix similarity index for the topic model\nindex_2 = MatrixSimilarity(model_2[ingredient_bow])\n\n","metadata":{"execution":{"iopub.status.busy":"2023-03-13T12:27:42.990795Z","iopub.execute_input":"2023-03-13T12:27:42.992141Z","iopub.status.idle":"2023-03-13T12:27:49.034245Z","shell.execute_reply.started":"2023-03-13T12:27:42.992086Z","shell.execute_reply":"2023-03-13T12:27:49.033024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"text-align:center;background-color:#1F618D; color:white\" >VEGAN</h2>\n<div class=\"alert alert-info\" role=\"alert\">\n    This model will be recommendating from the data set conating all the vegan recipes\n</div>","metadata":{}},{"cell_type":"code","source":"\n#Generating a dictionary from the one-hot encoded ingredients\ningredient_dict_3 = Dictionary(df_diet_vegan['ingredients'].apply(lambda x: x.split()))\n\n#Generating a bag-of-words representation of the ingredient data\ningredient_bow = [ingredient_dict_3.doc2bow(recipe.split()) for recipe in df_diet_vegan['ingredients']]\n\n#Creating an LSI topic model from the ingredient data\nmodel_3 = LsiModel(corpus=ingredient_bow, id2word=ingredient_dict_3, num_topics=len(df_diet_vegan['ingredients']))\n\n#Creating a matrix similarity index for the topic model\nindex_3 = MatrixSimilarity(model_3[ingredient_bow])\n","metadata":{"execution":{"iopub.status.busy":"2023-03-13T12:27:49.036021Z","iopub.execute_input":"2023-03-13T12:27:49.037324Z","iopub.status.idle":"2023-03-13T12:27:53.694458Z","shell.execute_reply.started":"2023-03-13T12:27:49.037270Z","shell.execute_reply":"2023-03-13T12:27:53.693259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"text-align:center;background-color:#5499C7; color:white\" >This dictionary will be used to select the appropriate model for recommendation system</h2>","metadata":{}},{"cell_type":"code","source":"model_dict = {\"suprise\":0,\"non-veg\":1,\"veg\":2,\"vegan\":3}","metadata":{"execution":{"iopub.status.busy":"2023-03-13T12:27:53.695945Z","iopub.execute_input":"2023-03-13T12:27:53.696358Z","iopub.status.idle":"2023-03-13T12:27:53.701671Z","shell.execute_reply.started":"2023-03-13T12:27:53.696312Z","shell.execute_reply":"2023-03-13T12:27:53.700676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a function to get the top n similar recipes based on user ingredients\ndef get_recipes_by_ingredients(ingredients, n,model):\n    \"\"\"\n    Given a list of ingredients, return a dataframe of n recommended recipes based on the similarity \n    of the ingredients to those in the dataset, for a specific diet type.\n\n    Args:\n    - ingredients (list): A list of ingredients.\n    - n (int): The number of recommended recipes to return.\n    - model (str): A string indicating the diet type to consider. \n                   Possible values: 'suprise', 'non-veg', 'veg', 'vegan'.\n\n    Returns:\n    - recommends (DataFrame): A Pandas DataFrame containing the n recommended recipes.\n    \"\"\"\n    if model_dict.get(model) == 0:\n        # Convert the user ingredients to bag-of-words representation\n        ingredient_bow = ingredient_dict_0.doc2bow(ingredients)\n\n        # Get the topic distribution for the user ingredients\n        user_topics = model_0[ingredient_bow]\n\n        # Get the similarity scores for all recipes based on user ingredients\n        sim_scores = index_0[user_topics]\n\n        # Sort the recipes by similarity score\n        sim_scores = sorted(enumerate(sim_scores), key=lambda x: x[1], reverse=True)\n\n        # Get the top n similar recipes\n        sim_scores = sim_scores[0:n]\n        recipe_indices = [i[0] for i in sim_scores]\n        recommends = df_diet.iloc[recipe_indices]\n        recommends = recommends.reset_index(drop = True)\n        return recommends\n    if model_dict.get(model) == 1:\n        # Convert the user ingredients to bag-of-words representation\n        ingredient_bow = ingredient_dict_1.doc2bow(ingredients)\n\n        # Get the topic distribution for the user ingredients\n        user_topics = model_1[ingredient_bow]\n\n        # Get the similarity scores for all recipes based on user ingredients\n        sim_scores = index_1[user_topics]\n\n        # Sort the recipes by similarity score\n        sim_scores = sorted(enumerate(sim_scores), key=lambda x: x[1], reverse=True)\n\n        # Get the top n similar recipes\n        sim_scores = sim_scores[0:n]\n        recipe_indices = [i[0] for i in sim_scores]\n        recommends = df_diet_non_veg.iloc[recipe_indices]\n        recommends = recommends.reset_index(drop = True)\n        return recommends\n    if model_dict.get(model) == 2:\n        # Convert the user ingredients to bag-of-words representation\n        ingredient_bow = ingredient_dict_2.doc2bow(ingredients)\n\n        # Get the topic distribution for the user ingredients\n        user_topics = model_2[ingredient_bow]\n\n        # Get the similarity scores for all recipes based on user ingredients\n        sim_scores = index_2[user_topics]\n\n        # Sort the recipes by similarity score\n        sim_scores = sorted(enumerate(sim_scores), key=lambda x: x[1], reverse=True)\n\n        # Get the top n similar recipes\n        sim_scores = sim_scores[0:n]\n        recipe_indices = [i[0] for i in sim_scores]\n        recommends = df_diet_veg.iloc[recipe_indices]\n        recommends = recommends.reset_index(drop = True)\n        return recommends\n    if model_dict.get(model) == 3:\n        # Convert the user ingredients to bag-of-words representation\n        ingredient_bow = ingredient_dict_3.doc2bow(ingredients)\n\n        # Get the topic distribution for the user ingredients\n        user_topics = model_3[ingredient_bow]\n\n        # Get the similarity scores for all recipes based on user ingredients\n        sim_scores = index_3[user_topics]\n\n        # Sort the recipes by similarity score\n        sim_scores = sorted(enumerate(sim_scores), key=lambda x: x[1], reverse=True)\n\n        # Get the top n similar recipes\n        sim_scores = sim_scores[0:n]\n        recipe_indices = [i[0] for i in sim_scores]\n        recommends = df_diet_vegan.iloc[recipe_indices]\n        recommends = recommends.reset_index(drop = True)\n        return recommends","metadata":{"execution":{"iopub.status.busy":"2023-03-13T12:27:53.703063Z","iopub.execute_input":"2023-03-13T12:27:53.703416Z","iopub.status.idle":"2023-03-13T12:27:53.719833Z","shell.execute_reply.started":"2023-03-13T12:27:53.703381Z","shell.execute_reply":"2023-03-13T12:27:53.718475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ningredients = ['chicken', 'cheese','butter','garlic']\nget_recipes_by_ingredients(ingredients, n=10,model ='non-veg')","metadata":{"execution":{"iopub.status.busy":"2023-03-13T12:28:53.788831Z","iopub.execute_input":"2023-03-13T12:28:53.789261Z","iopub.status.idle":"2023-03-13T12:28:53.845798Z","shell.execute_reply.started":"2023-03-13T12:28:53.789225Z","shell.execute_reply":"2023-03-13T12:28:53.843985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ingredients = ['salmon','butter']\nget_recipes_by_ingredients(ingredients, n=10,model ='veg')","metadata":{"execution":{"iopub.status.busy":"2023-03-13T12:29:45.466614Z","iopub.execute_input":"2023-03-13T12:29:45.467066Z","iopub.status.idle":"2023-03-13T12:29:45.511103Z","shell.execute_reply.started":"2023-03-13T12:29:45.467026Z","shell.execute_reply":"2023-03-13T12:29:45.509180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-info\" role=\"alert\">\n    The below code saves the <b>LSI models</b>, similarity indices, and dictionaries for each diet type as separate files, so they can be loaded and reused later in web deployment code.\n</div>","metadata":{}},{"cell_type":"code","source":"model_0.save('model_0')\nindex_0.save('index_0')\ningredient_dict_0.save('ingredient_dict_0.dict')\nmodel_1.save('model_1')\nindex_1.save('index_1')\ningredient_dict_1.save('ingredient_dict_1.dict')\nmodel_2.save('model_2')\nindex_2.save('index_2')\ningredient_dict_2.save('ingredient_dict_2.dict')\nmodel_3.save('model_3')\nindex_3.save('index_3')\ningredient_dict_0.save('ingredient_dict_3.dict')","metadata":{"execution":{"iopub.status.busy":"2023-03-13T12:27:53.861696Z","iopub.execute_input":"2023-03-13T12:27:53.863121Z","iopub.status.idle":"2023-03-13T12:27:54.084660Z","shell.execute_reply.started":"2023-03-13T12:27:53.863065Z","shell.execute_reply":"2023-03-13T12:27:54.083492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<nav aria-label=\"The Sentient Chef\">\n  <ul class=\"pagination\">\n    <li class=\"page-item\"><a class=\"page-link\" href=\"https://www.kaggle.com/code/karthikrathod/the-sentient-chef-scrapping-notebook\">1. Setting Sail on the Recipe Hunt </a></li>\n    <li class=\"page-item\"><a class=\"page-link\" href=\"#\">2. Navigating the Choppy Waters of Preprocessing</a></li>\n    <li class=\"page-item\"><a class=\"page-link\" href=\"https://www.kaggle.com/karthikrathod/the-sentient-chef-eda\">3. Surveying the Seas of Recipe Data</a></li>\n    <li class=\"page-item\"><a class=\"page-link\" href=\"https://www.kaggle.com/swarnava007/the-sentient-chef-maps\">4. Mapping the Culinary World </a></li>\n    <li class=\"page-item\"><a class=\"page-link\" href=\"https://www.kaggle.com/code/karthikrathod/recipes-recommendation\">5. Sailing Towards Sentience üìå</a></li>\n  </ul>\n</nav>","metadata":{}}]}